{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45004b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862f3ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up dataset: vicon_room_1\n",
      "Downloading from http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_01_easy/V1_01_easy.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vicon_room_1: 100%|████████████████████████| 1.15G/1.15G [01:31<00:00, 12.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping into ../data/vicon_room_1...\n",
      "Removing archive...\n",
      "✅ Dataset 'vicon_room_1' ready in ../data/vicon_room_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_dataset(name, url):\n",
    "    data_dir = os.path.join(\"..\", \"data\", name)\n",
    "    zip_path = os.path.join(data_dir, f\"{name}.zip\")\n",
    "\n",
    "    print(f\"Setting up dataset: {name}\")\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # Streamed download with progress bar\n",
    "    print(f\"Downloading from {url}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "    with open(zip_path, \"wb\") as f, tqdm(\n",
    "        total=total_size, unit='B', unit_scale=True, desc=name, ncols=80\n",
    "    ) as pbar:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "            pbar.update(len(chunk))\n",
    "\n",
    "    # Unzip into the subdirectory\n",
    "    print(f\"Unzipping into {data_dir}...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "\n",
    "    # Remove the zip file\n",
    "    print(\"Removing archive...\")\n",
    "    os.remove(zip_path)\n",
    "\n",
    "    print(f\"✅ Dataset '{name}' ready in {data_dir}\")\n",
    "\n",
    "# Example usage\n",
    "download_dataset(\n",
    "    \"vicon_room_1\",\n",
    "    \"http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_01_easy/V1_01_easy.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51be410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prep_combined_csv(input_dir, output_filepath):\n",
    "    def load_and_clean_csv(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df.rename(columns={\n",
    "            '#timestamp [ns]': 'timestamp',\n",
    "            '#timestamp': 'timestamp',\n",
    "            'p_RS_R_x [m]': 'p_x',\n",
    "            'p_RS_R_y [m]': 'p_y',\n",
    "            'p_RS_R_z [m]': 'p_z',\n",
    "            'q_RS_x []': 'q_x',\n",
    "            'q_RS_y []': 'q_y',\n",
    "            'q_RS_z []': 'q_z',\n",
    "            'q_RS_w []': 'q_w',\n",
    "            'w_RS_S_x [rad s^-1]': 'w_x',\n",
    "            'w_RS_S_y [rad s^-1]': 'w_y',\n",
    "            'w_RS_S_z [rad s^-1]': 'w_z',\n",
    "            'a_RS_S_x [m s^-2]': 'a_x',\n",
    "            'a_RS_S_y [m s^-2]': 'a_y',\n",
    "            'a_RS_S_z [m s^-2]': 'a_z',\n",
    "        }, inplace=True)\n",
    "        df['timestamp'] = df['timestamp'].astype(np.int64)\n",
    "        df.sort_values('timestamp', inplace=True)\n",
    "        return df\n",
    "\n",
    "    # Load and clean\n",
    "    cam0_df = load_and_clean_csv(os.path.join(input_dir, 'cam0', 'data.csv'))\n",
    "    cam1_df = load_and_clean_csv(os.path.join(input_dir, 'cam1', 'data.csv'))\n",
    "    imu_df  = load_and_clean_csv(os.path.join(input_dir, 'imu0', 'data.csv'))\n",
    "    gt_df   = load_and_clean_csv(os.path.join(input_dir, 'state_groundtruth_estimate0', 'data.csv'))\n",
    "\n",
    "    # Merge cam0 and cam1 by outer join\n",
    "    combined = pd.merge(cam0_df, cam1_df, on='timestamp', how='outer', suffixes=('_cam0', '_cam1'))\n",
    "    combined.sort_values('timestamp', inplace=True)\n",
    "    combined['filename_cam0'] = combined['filename_cam0'].ffill()\n",
    "    combined['filename_cam1'] = combined['filename_cam1'].ffill()\n",
    "\n",
    "    # Interpolate IMU and GT to match combined camera timestamps\n",
    "    ref_timestamps = combined['timestamp']\n",
    "\n",
    "    imu_interp = imu_df.set_index('timestamp').reindex(ref_timestamps, method='nearest').reset_index()\n",
    "    gt_interp = gt_df.set_index('timestamp').reindex(ref_timestamps, method='nearest').reset_index()\n",
    "\n",
    "    # Merge interpolated IMU/GT back into combined frame table\n",
    "    combined = combined.merge(imu_interp, on='timestamp', how='left', suffixes=('', '_imu'))\n",
    "    combined = combined.merge(gt_interp, on='timestamp', how='left', suffixes=('', '_gt'))\n",
    "\n",
    "    # Optional: drop rows where GT data is still missing (e.g. beginning or end of run)\n",
    "    combined.dropna(subset=['p_x', 'q_x'], inplace=True)\n",
    "\n",
    "    # Final structure\n",
    "    output = combined[['timestamp', 'filename_cam0', 'filename_cam1', 'p_x', 'p_y', 'p_z', 'q_x', 'q_y', 'q_z', 'q_w', 'w_x', 'w_y', 'w_z', 'a_x', 'a_y', 'a_z']] \n",
    "    output.to_csv(output_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b78e5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_combined_csv(\"../data/vicon_room_1/mav0\", \"../data/vicon_room_1/combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4cd820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class IMUImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, cam0_image_root, cam1_image_root, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.cam0_image_root = cam0_image_root\n",
    "        self.cam1_image_root = cam1_image_root\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        cam0_path = os.path.join(self.cam0_image_root, row['filename_cam0'])\n",
    "        cam0_image = Image.open(cam0_path).convert(\"RGB\")\n",
    "        cam0_image = self.transform(cam0_image)\n",
    "\n",
    "        cam1_path = os.path.join(self.cam1_image_root, row['filename_cam1'])\n",
    "        cam1_image = Image.open(cam1_path).convert(\"RGB\")\n",
    "        cam1_image = self.transform(cam1_image)\n",
    "\n",
    "        # Load IMU features\n",
    "        imu = row[[\"w_x\", \"w_y\", \"w_z\", \"a_x\", \"a_y\", \"a_z\"]].values.astype(\"float32\")\n",
    "        imu_tensor = torch.tensor(imu)\n",
    "\n",
    "        # Load ground truth features\n",
    "        ground_truth = row[[\"p_x\", \"p_y\", \"p_z\", \"q_x\", \"q_y\", \"q_z\", \"q_w\"]].values.astype(\"float32\")\n",
    "        ground_truth_tensor = torch.tensor(ground_truth)\n",
    "\n",
    "        return [imu_tensor, cam0_image, cam1_image], ground_truth_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693f1fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU Data: tensor([-2.0944e-03,  1.7453e-02,  7.7493e-02,  9.0875e+00,  1.3076e-01,\n",
      "        -3.6938e+00])\n",
      "Camera 0 Image Shape: torch.Size([224, 224])\n",
      "Camera 1 Image Shape: torch.Size([224, 224])\n",
      "Ground Truth: tensor([ 0.8786,  2.1425,  0.9473, -0.8285, -0.0590, -0.5536,  0.0605])\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "dataset = IMUImageDataset(\n",
    "    csv_path=\"../data/vicon_room_1/combined.csv\",\n",
    "    cam0_image_root=\"../data/vicon_room_1/mav0/cam0/data\",\n",
    "    cam1_image_root=\"../data/vicon_room_1/mav0/cam1/data\"\n",
    ")\n",
    "inputs, labels = dataset[0]\n",
    "imu_data, cam0_images, cam1_images = inputs\n",
    "print(\"IMU Data:\", imu_data)\n",
    "print(\"Camera 0 Image Shape:\", cam0_images[0].shape)\n",
    "print(\"Camera 1 Image Shape:\", cam1_images[0].shape)\n",
    "print(\"Ground Truth:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca37a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequence(aStartPos : int, aEndPos : int, dataset : IMUImageDataset) -> dict[str, torch.Tensor]:\n",
    "    data = [dataset[i] for i in range(aStartPos, aEndPos)]\n",
    "    inputs, labels = zip(*data)\n",
    "    imu_data, cam0_images, cam1_images = zip(*inputs)\n",
    "    imu_data = torch.stack(imu_data)    \n",
    "    cam0_images = torch.stack(cam0_images)\n",
    "    cam1_images = torch.stack(cam1_images)\n",
    "    labels = torch.stack(labels)\n",
    "    return [imu_data, cam0_images, cam1_images], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024621db",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example usage of build_sequence\u001b[39;00m\n\u001b[32m      2\u001b[39m data = build_sequence(\u001b[32m0\u001b[39m, \u001b[32m10\u001b[39m, dataset)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimu_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.shape)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(data[\u001b[33m\"\u001b[39m\u001b[33mcam0_images\u001b[39m\u001b[33m\"\u001b[39m].shape)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(data[\u001b[33m\"\u001b[39m\u001b[33mcam1_images\u001b[39m\u001b[33m\"\u001b[39m].shape)\n",
      "\u001b[31mTypeError\u001b[39m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Example usage of build_sequence\n",
    "x,y = build_sequence(0, 10, dataset)\n",
    "train_x, train_cam0, train_cam1 = x\n",
    "print(\"IMU Data Shape:\", train_x.shape)\n",
    "print(\"Camera 0 Images Shape:\", train_cam0.shape)\n",
    "print(\"Camera 1 Images Shape:\", train_cam1.shape)\n",
    "print(\"Labels Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd5db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
