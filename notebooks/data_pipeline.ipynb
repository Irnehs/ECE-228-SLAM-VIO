{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45004b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862f3ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up dataset: vicon_room_1\n",
      "Downloading from http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_01_easy/V1_01_easy.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vicon_room_1: 100%|████████████████████████| 1.15G/1.15G [01:31<00:00, 12.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping into ../data/vicon_room_1...\n",
      "Removing archive...\n",
      "✅ Dataset 'vicon_room_1' ready in ../data/vicon_room_1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_dataset(name, url):\n",
    "    data_dir = os.path.join(\"..\", \"data\", name)\n",
    "    zip_path = os.path.join(data_dir, f\"{name}.zip\")\n",
    "\n",
    "    print(f\"Setting up dataset: {name}\")\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # Streamed download with progress bar\n",
    "    print(f\"Downloading from {url}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    with open(zip_path, \"wb\") as f, tqdm(\n",
    "        total=total_size, unit=\"B\", unit_scale=True, desc=name, ncols=80\n",
    "    ) as pbar:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "            pbar.update(len(chunk))\n",
    "\n",
    "    # Unzip into the subdirectory\n",
    "    print(f\"Unzipping into {data_dir}...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "\n",
    "    # Remove the zip file\n",
    "    print(\"Removing archive...\")\n",
    "    os.remove(zip_path)\n",
    "\n",
    "    print(f\"✅ Dataset '{name}' ready in {data_dir}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "download_dataset(\n",
    "    \"vicon_room_1\",\n",
    "    \"http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_01_easy/V1_01_easy.zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51be410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def prep_combined_csv(input_dir, output_filepath):\n",
    "    def load_and_clean_csv(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"#timestamp [ns]\": \"timestamp\",\n",
    "                \"#timestamp\": \"timestamp\",\n",
    "                \"p_RS_R_x [m]\": \"p_x\",\n",
    "                \"p_RS_R_y [m]\": \"p_y\",\n",
    "                \"p_RS_R_z [m]\": \"p_z\",\n",
    "                \"q_RS_x []\": \"q_x\",\n",
    "                \"q_RS_y []\": \"q_y\",\n",
    "                \"q_RS_z []\": \"q_z\",\n",
    "                \"q_RS_w []\": \"q_w\",\n",
    "                \"w_RS_S_x [rad s^-1]\": \"w_x\",\n",
    "                \"w_RS_S_y [rad s^-1]\": \"w_y\",\n",
    "                \"w_RS_S_z [rad s^-1]\": \"w_z\",\n",
    "                \"a_RS_S_x [m s^-2]\": \"a_x\",\n",
    "                \"a_RS_S_y [m s^-2]\": \"a_y\",\n",
    "                \"a_RS_S_z [m s^-2]\": \"a_z\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        df[\"timestamp\"] = df[\"timestamp\"].astype(np.int64)\n",
    "        df.sort_values(\"timestamp\", inplace=True)\n",
    "        return df\n",
    "\n",
    "    # Load and clean\n",
    "    cam0_df = load_and_clean_csv(os.path.join(input_dir, \"cam0\", \"data.csv\"))\n",
    "    cam1_df = load_and_clean_csv(os.path.join(input_dir, \"cam1\", \"data.csv\"))\n",
    "    imu_df = load_and_clean_csv(os.path.join(input_dir, \"imu0\", \"data.csv\"))\n",
    "    gt_df = load_and_clean_csv(\n",
    "        os.path.join(input_dir, \"state_groundtruth_estimate0\", \"data.csv\")\n",
    "    )\n",
    "\n",
    "    # Merge cam0 and cam1 by outer join\n",
    "    combined = pd.merge(\n",
    "        cam0_df, cam1_df, on=\"timestamp\", how=\"outer\", suffixes=(\"_cam0\", \"_cam1\")\n",
    "    )\n",
    "    combined.sort_values(\"timestamp\", inplace=True)\n",
    "    combined[\"filename_cam0\"] = combined[\"filename_cam0\"].ffill()\n",
    "    combined[\"filename_cam1\"] = combined[\"filename_cam1\"].ffill()\n",
    "\n",
    "    # Interpolate IMU and GT to match combined camera timestamps\n",
    "    ref_timestamps = combined[\"timestamp\"]\n",
    "\n",
    "    imu_interp = (\n",
    "        imu_df.set_index(\"timestamp\")\n",
    "        .reindex(ref_timestamps, method=\"nearest\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    gt_interp = (\n",
    "        gt_df.set_index(\"timestamp\")\n",
    "        .reindex(ref_timestamps, method=\"nearest\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Merge interpolated IMU/GT back into combined frame table\n",
    "    combined = combined.merge(\n",
    "        imu_interp, on=\"timestamp\", how=\"left\", suffixes=(\"\", \"_imu\")\n",
    "    )\n",
    "    combined = combined.merge(\n",
    "        gt_interp, on=\"timestamp\", how=\"left\", suffixes=(\"\", \"_gt\")\n",
    "    )\n",
    "\n",
    "    # Optional: drop rows where GT data is still missing (e.g. beginning or end of run)\n",
    "    combined.dropna(subset=[\"p_x\", \"q_x\"], inplace=True)\n",
    "\n",
    "    # Final structure\n",
    "    output = combined[\n",
    "        [\n",
    "            \"timestamp\",\n",
    "            \"filename_cam0\",\n",
    "            \"filename_cam1\",\n",
    "            \"p_x\",\n",
    "            \"p_y\",\n",
    "            \"p_z\",\n",
    "            \"q_x\",\n",
    "            \"q_y\",\n",
    "            \"q_z\",\n",
    "            \"q_w\",\n",
    "            \"w_x\",\n",
    "            \"w_y\",\n",
    "            \"w_z\",\n",
    "            \"a_x\",\n",
    "            \"a_y\",\n",
    "            \"a_z\",\n",
    "        ]\n",
    "    ]\n",
    "    output.to_csv(output_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78e5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_combined_csv(\"../data/vicon_room_1/mav0\", \"../data/vicon_room_1/combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4cd820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "class IMUImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, cam0_image_root, cam1_image_root, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.cam0_image_root = cam0_image_root\n",
    "        self.cam1_image_root = cam1_image_root\n",
    "        self.transform = transform or transforms.Compose(\n",
    "            [transforms.Resize((224, 224)), transforms.ToTensor()]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        cam0_path = os.path.join(self.cam0_image_root, row[\"filename_cam0\"])\n",
    "        cam0_image = Image.open(cam0_path).convert(\"RGB\")\n",
    "        cam0_image = self.transform(cam0_image)\n",
    "\n",
    "        cam1_path = os.path.join(self.cam1_image_root, row[\"filename_cam1\"])\n",
    "        cam1_image = Image.open(cam1_path).convert(\"RGB\")\n",
    "        cam1_image = self.transform(cam1_image)\n",
    "\n",
    "        # Load IMU features\n",
    "        imu = row[[\"w_x\", \"w_y\", \"w_z\", \"a_x\", \"a_y\", \"a_z\"]].values.astype(\"float32\")\n",
    "        imu_tensor = torch.tensor(imu)\n",
    "\n",
    "        # Load ground truth features\n",
    "        ground_truth = row[\n",
    "            [\"p_x\", \"p_y\", \"p_z\", \"q_x\", \"q_y\", \"q_z\", \"q_w\"]\n",
    "        ].values.astype(\"float32\")\n",
    "        ground_truth_tensor = torch.tensor(ground_truth)\n",
    "\n",
    "        return [imu_tensor, cam0_image, cam1_image], ground_truth_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "693f1fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU Data: tensor([-2.0944e-03,  1.7453e-02,  7.7493e-02,  9.0875e+00,  1.3076e-01,\n",
      "        -3.6938e+00])\n",
      "Camera 0 Image Shape: torch.Size([224, 224])\n",
      "Camera 1 Image Shape: torch.Size([224, 224])\n",
      "Ground Truth: tensor([ 0.8786,  2.1425,  0.9473, -0.8285, -0.0590, -0.5536,  0.0605])\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "import pandas as pd\n",
    "import os\n",
    "dataset = IMUImageDataset(\n",
    "    csv_path=\"../data/vicon_room_1/combined.csv\",\n",
    "    cam0_image_root=\"../data/vicon_room_1/mav0/cam0/data\",\n",
    "    cam1_image_root=\"../data/vicon_room_1/mav0/cam1/data\",\n",
    ")\n",
    "inputs, labels = dataset[0]\n",
    "imu_data, cam0_images, cam1_images = inputs\n",
    "print(\"IMU Data:\", imu_data)\n",
    "print(\"Camera 0 Image Shape:\", cam0_images[0].shape)\n",
    "print(\"Camera 1 Image Shape:\", cam1_images[0].shape)\n",
    "print(\"Ground Truth:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ca37a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequence(\n",
    "    aStartPos: int, aEndPos: int, dataset: IMUImageDataset\n",
    ") -> dict[str, torch.Tensor]:\n",
    "    data = [dataset[i] for i in range(aStartPos, aEndPos)]\n",
    "    inputs, labels = zip(*data)\n",
    "    imu_data, cam0_images, cam1_images = zip(*inputs)\n",
    "    imu_data = torch.stack(imu_data)\n",
    "    cam0_images = torch.stack(cam0_images)\n",
    "    cam1_images = torch.stack(cam1_images)\n",
    "    labels = torch.stack(labels)\n",
    "    return [imu_data, cam0_images, cam1_images], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "024621db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU Data Shape: torch.Size([10, 6])\n",
      "Camera 0 Images Shape: torch.Size([10, 3, 224, 224])\n",
      "Camera 1 Images Shape: torch.Size([10, 3, 224, 224])\n",
      "Labels Shape: torch.Size([10, 7])\n"
     ]
    }
   ],
   "source": [
    "# Example usage of build_sequence\n",
    "x, y = build_sequence(0, 10, dataset)\n",
    "train_x, train_cam0, train_cam1 = x\n",
    "print(\"IMU Data Shape:\", train_x.shape)\n",
    "print(\"Camera 0 Images Shape:\", train_cam0.shape)\n",
    "print(\"Camera 1 Images Shape:\", train_cam1.shape)\n",
    "print(\"Labels Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaeab54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch(\n",
    "        aStartPos: int, aEndPos: int, sequenceLength :int, dataset: IMUImageDataset\n",
    "):\n",
    "    batch = []\n",
    "    for i in range(aStartPos, aEndPos, sequenceLength):\n",
    "        end_pos = min(i + sequenceLength, aEndPos)\n",
    "        if end_pos - i == sequenceLength:  # Ensure full sequence length\n",
    "            batch.append(build_sequence(i, end_pos, dataset))\n",
    "    # Convert to tensors\n",
    "    if not batch:\n",
    "        return None  # No valid sequences found\n",
    "    imu_data, cam0_images, cam1_images = zip(*[b[0] for b in batch])\n",
    "    labels = torch.stack([b[1] for b in batch])\n",
    "    imu_data = torch.stack(imu_data)\n",
    "    cam0_images = torch.stack(cam0_images)\n",
    "    cam1_images = torch.stack(cam1_images)\n",
    "    return [imu_data, cam0_images, cam1_images], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be2d9270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch IMU Data Shape: torch.Size([10, 10, 6])\n",
      "Batch Camera 0 Images Shape: torch.Size([10, 10, 3, 224, 224])\n",
      "Batch Camera 1 Images Shape: torch.Size([10, 10, 3, 224, 224])\n",
      "Batch Labels Shape: torch.Size([10, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "batch = build_batch(0, 100, 10, dataset)\n",
    "if batch is not None:\n",
    "    x, y = batch\n",
    "    train_imu, train_cam0, train_cam1 = x\n",
    "    print(\"Batch IMU Data Shape:\", train_imu.shape)\n",
    "    print(\"Batch Camera 0 Images Shape:\", train_cam0.shape)\n",
    "    print(\"Batch Camera 1 Images Shape:\", train_cam1.shape)\n",
    "    print(\"Batch Labels Shape:\", y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece228-slam-vio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
